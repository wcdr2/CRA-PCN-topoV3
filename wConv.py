import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.nn.modules.utils import _single, _pair, _triple


class wConv1d(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, den, stride=1, padding=2, groups=1, dilation=1,
                 bias=False):
        super(wConv1d, self).__init__()
        self.stride = _single(stride)
        self.padding = _single(padding)
        self.kernel_size = _single(kernel_size)
        self.groups = groups
        self.dilation = _single(dilation)
        self.weight = nn.Parameter(torch.empty(out_channels, in_channels // groups, *self.kernel_size))
        nn.init.kaiming_normal_(self.weight, mode='fan_out', nonlinearity='relu')
        self.bias = nn.Parameter(torch.zeros(out_channels)) if bias else None

        device = torch.device('cpu')
        self.register_buffer('alfa', torch.cat([torch.tensor(den, device=device), torch.tensor([1.0], device=device),
                                                torch.flip(torch.tensor(den, device=device), dims=[0])]))
        self.register_buffer('Phi', self.alfa)

        if self.Phi.shape != self.kernel_size:
            raise ValueError(f"Phi shape {self.Phi.shape} must match kernel size {self.kernel_size}")

    def forward(self, x):
        Phi = self.Phi.to(x.device)
        weight_Phi = self.weight * Phi
        return F.conv1d(x, weight_Phi, bias=self.bias, stride=self.stride, padding=self.padding, groups=self.groups,
                        dilation=self.dilation)


class wConv2d(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, den, stride=1, padding=2, groups=1, dilation=1,
                 bias=False):
        super(wConv2d, self).__init__()
        self.stride = _pair(stride)
        self.padding = _pair(padding)
        self.kernel_size = _pair(kernel_size)
        self.groups = groups
        self.dilation = _pair(dilation)
        self.weight = nn.Parameter(torch.empty(out_channels, in_channels // groups, *self.kernel_size))
        nn.init.kaiming_normal_(self.weight, mode='fan_out', nonlinearity='relu')
        self.bias = nn.Parameter(torch.zeros(out_channels)) if bias else None

        device = torch.device('cpu')
        self.register_buffer('alfa', torch.cat([torch.tensor(den, device=device), torch.tensor([1.0], device=device),
                                                torch.flip(torch.tensor(den, device=device), dims=[0])]))
        self.register_buffer('Phi', torch.outer(self.alfa, self.alfa))

        if self.Phi.shape != self.kernel_size:
            raise ValueError(f"Phi shape {self.Phi.shape} must match kernel size {self.kernel_size}")

    def forward(self, x):
        Phi = self.Phi.to(x.device)
        weight_Phi = self.weight * Phi
        return F.conv2d(x, weight_Phi, bias=self.bias, stride=self.stride, padding=self.padding, groups=self.groups,
                        dilation=self.dilation)


class wConv3d(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, den, stride=1, padding=2, groups=1, dilation=1,
                 bias=False):
        super(wConv3d, self).__init__()
        self.stride = _triple(stride)
        self.padding = _triple(padding)
        self.kernel_size = _triple(kernel_size)
        self.groups = groups
        self.dilation = _triple(dilation)
        self.weight = nn.Parameter(torch.empty(out_channels, in_channels // groups, *self.kernel_size))
        nn.init.kaiming_normal_(self.weight, mode='fan_out', nonlinearity='relu')
        self.bias = nn.Parameter(torch.zeros(out_channels)) if bias else None

        device = torch.device('cpu')
        self.register_buffer('alfa', torch.cat([torch.tensor(den, device=device), torch.tensor([1.0], device=device),
                                                torch.flip(torch.tensor(den, device=device), dims=[0])]))
        self.register_buffer('Phi', torch.einsum('i,j,k->ijk', self.alfa, self.alfa, self.alfa))

        if self.Phi.shape != self.kernel_size:
            raise ValueError(f"Phi shape {self.Phi.shape} must match kernel size {self.kernel_size}")

    def forward(self, x):
        Phi = self.Phi.to(x.device)
        weight_Phi = self.weight * Phi
        return F.conv3d(x, weight_Phi, bias=self.bias, stride=self.stride, padding=self.padding, groups=self.groups,
                        dilation=self.dilation)


if __name__ == '__main__':
    # Test wConv1d
    print("Testing wConv1d...")
    den = [0.5, 0.75]
    block = wConv1d(in_channels=3, out_channels=3, kernel_size=5, den=den).to('cuda')
    input = torch.rand(1, 3, 32).to('cuda')
    output = block(input)
    print("Input size:", input.size())
    print("Output size:", output.size())
    print()

    # Test wConv2d
    print("Testing wConv2d...")
    den = [0.5, 0.75]
    block = wConv2d(in_channels=3, out_channels=3, kernel_size=5, den=den).to('cuda')
    input = torch.rand(1, 3, 32, 32).to('cuda')
    output = block(input)
    print("Input size:", input.size())
    print("Output size:", output.size())
    print()

    # Test wConv3d
    print("Testing wConv3d...")
    den = [0.5, 0.75]
    block = wConv3d(in_channels=3, out_channels=3, kernel_size=5, den=den).to('cuda')
    input = torch.rand(1, 3, 32, 32, 32).to('cuda')
    output = block(input)
    print("Input size:", input.size())
    print("Output size:", output.size())


"""
====================================================================
ğŸ§© Weighted Convolution (wConv1d / wConv2d / wConv3d) æ¨¡å—è¯´æ˜
====================================================================

è¿™äº›æ¨¡å—æ˜¯å¸¦æƒå·ç§¯æ“ä½œçš„æ‰©å±•ç‰ˆæœ¬ï¼Œåˆ†åˆ«å¤„ç† 1Dã€2Dã€3D æ•°æ®ã€‚é€šè¿‡åœ¨å¸¸è§„å·ç§¯æ ¸ä¸Šå¼•å…¥åŠ æƒçŸ©é˜µï¼ˆÎ¦ï¼‰ï¼Œ
å®ç°å¯¹è¾“å…¥ä¿¡å·çš„åŒºåŸŸæ€§åŠ æƒå»ºæ¨¡ï¼Œå¯å¢å¼ºç½‘ç»œå¯¹ä¸åŒåŒºåŸŸç‰¹å¾çš„æ•æ„Ÿåº¦ã€‚

====================================================================
âœ… æ¨¡å—åˆ›æ–°ç‚¹
====================================================================

1. ç©ºé—´æƒé‡è°ƒåˆ¶ï¼ˆWeighted Kernel Modulationï¼‰:
   - ä½¿ç”¨ den å‚æ•°ç”Ÿæˆä¸€ä¸ªå¯¹ç§°çš„æƒé‡åºåˆ— `alfa`ã€‚
   - æ„é€ å‡ºæƒé‡æ¨¡æ¿ `Phi`ï¼Œå¹¶ä¸å·ç§¯æ ¸é€å…ƒç´ ç›¸ä¹˜ï¼Œå®ç°ä½ç½®æ•æ„Ÿçš„å·ç§¯è®¡ç®—ã€‚

2. å¤šç»´é€šç”¨æ€§ï¼ˆ1D/2D/3Dï¼‰ç»Ÿä¸€è®¾è®¡:
   - åˆ†åˆ«é‡‡ç”¨ `torch.outer` å’Œ `torch.einsum` æ„é€  Phiï¼Œå®ç°ä»ä¸€ç»´åˆ°ä¸‰ç»´çš„ç»“æ„æ‰©å±•ã€‚
   - æ¥å£é£æ ¼ç»Ÿä¸€ï¼Œä¾¿äºåœ¨ä¸åŒç±»å‹çš„æ—¶åºã€å›¾åƒæˆ–ä½“ç§¯æ•°æ®ä¸­è°ƒç”¨ã€‚

3. åŠ¨æ€å¯è°ƒçš„ç©ºé—´å“åº”ï¼ˆFlexible Spatial Biasï¼‰:
   - é€šè¿‡ä¼ å…¥ä¸åŒçš„ `den` æƒé‡å¯†åº¦åºåˆ—ï¼Œå¯è‡ªç”±è°ƒæ§å·ç§¯æ ¸çš„å“åº”åŒºåŸŸå’Œé‡å¿ƒã€‚

4. ä¸æ ‡å‡†å·ç§¯å…¼å®¹ï¼ˆPlug-and-playï¼‰:
   - ä¿ç•™äº†æ ‡å‡†å·ç§¯çš„è¾“å…¥è¾“å‡ºå½¢å¼ã€groupsã€strideã€padding ç­‰å‚æ•°ã€‚
   - å¯æ— ç¼æ›¿ä»£ nn.Conv ç³»åˆ—æ¨¡å—ã€‚

====================================================================
ğŸš€ åº”ç”¨åœºæ™¯ä¸¾ä¾‹
====================================================================

1. æ—¶é—´åºåˆ—å»ºæ¨¡ï¼ˆwConv1dï¼‰:
   - å¯ç”¨äºè¯­éŸ³è¯†åˆ«ã€é‡‘èé¢„æµ‹ä¸­çš„å±€éƒ¨è¶‹åŠ¿å»ºæ¨¡ã€‚

2. å›¾åƒè¯†åˆ«ä¸åˆ†å‰²ï¼ˆwConv2dï¼‰:
   - åœ¨ç›®æ ‡æ£€æµ‹ã€å›¾åƒåˆ†å‰²ä¸­ç”¨äºåŠ å¼ºç©ºé—´åŒºåŸŸçš„ç‰¹å¾æå–ã€‚

3. åŒ»ç–—å½±åƒå¤„ç†ï¼ˆwConv3dï¼‰:
   - å¯¹ CT/MRI ç­‰ä½“æ•°æ®ä¸­çš„é‡è¦ä½“ç´ åŒºåŸŸèµ‹äºˆæ›´é«˜æƒé‡ï¼Œæé«˜è¯Šæ–­æ€§èƒ½ã€‚

4. é¥æ„Ÿä¸å¤šå…‰è°±å›¾åƒ:
   - åŠ å¼ºå¤šç»´å›¾åƒä¸­çš„ä¿¡æ¯èåˆï¼Œå¦‚å…‰è°±æƒé‡å»ºæ¨¡ã€‚

5. æ—¶ç©ºå»ºæ¨¡ä¸å›¾ç»“æ„å­¦ä¹ :
   - åœ¨ ST-GNN ç­‰æ¨¡å‹ä¸­ä½œä¸ºæ—¶ç©ºå±€éƒ¨å·ç§¯æ¨¡å—ä½¿ç”¨ã€‚

"""
